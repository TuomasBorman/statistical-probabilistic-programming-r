<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Introduction to Probabilistic Programming in R: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="site.webmanifest">
<link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Introduction to Probabilistic Programming in R
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="search button" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Introduction to Probabilistic Programming in R
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
<input class="form-control me-2 searchbox" type="search" placeholder="Search" aria-label="Search"><button class="btn btn-outline-success tablet-search-button" type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="search button"></i>
        </button>
      </fieldset>
</form>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Probabilistic Programming in R
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->
      
            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="setup.html">1. Setup</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="bayesian-statistics.html">2. Basics of Bayesian statistics</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="stan.html">3. Stan</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="mcmc.html">4. MCMC</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="hierarchical-models.html">5. Hierarchical Models</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="model-critisism.html">6. Model checking</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="gaussian-processes.html">7. Gaussian processes</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="other-topics.html">8. Other topics</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="recommended-reading.html">9. Recommended reading</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush11">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading11">
        <a href="exercises.html">10. exercises</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">
            
            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-setup"><p>Content from <a href="setup.html">Setup</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/setup.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<p>FIXME: Setup instructions live in this document. Please specify the
tools and the data sets the Learner needs to have installed.</p>
<section id="data-sets"><h2 class="section-heading">Data Sets<a class="anchor" aria-label="anchor" href="#data-sets"></a>
</h2>
<hr class="half-width">
<!--
FIXME: place any data you want learners to use in `episodes/data` and then use
       a relative link ( [data zip file](data/lesson-data.zip) ) to provide a
       link to it, replacing the example.com link.
--><p>Download the <a href="https://example.com/FIXME" class="external-link">data zip file</a>
and unzip it to your Desktop</p>
</section><section id="software-setup"><h2 class="section-heading">Software Setup<a class="anchor" aria-label="anchor" href="#software-setup"></a>
</h2>
<hr class="half-width">
<div id="details" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="details" class="callout-inner">
<h3 class="callout-title">Details<a class="anchor" aria-label="anchor" href="#details"></a>
</h3>
<div class="callout-content">
<p>Setup for different systems can be presented in dropdown menus via a
<code>solution</code> tag. They will join to this discussion block, so
you can give a general overview of the software used in this lesson here
and fill out the individual operating systems (and potentially add more,
e.g. online setup) in the solutions blocks.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Windows</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Use PuTTY</p>
</div>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">MacOS</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>Use Terminal.app</p>
</div>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3">Linux</h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>Use Terminal</p>
</div>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></section><section id="aio-bayesian-statistics"><p>Content from <a href="bayesian-statistics.html">Basics of Bayesian statistics</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/bayesian-statistics.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is Bayesian statistics?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Basic idea of Bayesian statistical thinking</li>
<li>Bayesian formula: prior, likelihood, posterior</li>
<li>Grid approximation</li>
<li>Communicating posterior information
<ul>
<li>Point estimates</li>
<li>Intervals</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="bayes-formula"><h2 class="section-heading">Bayes’ formula<a class="anchor" aria-label="anchor" href="#bayes-formula"></a>
</h2>
<hr class="half-width">
<p>The fundamental ingredient of Bayesian statistics and probabilistic
thinking is the Bayes’ theorem, stated as</p>
<p><span class="math display">\[
  p(\theta | X) = \frac{p(\theta)  p(X | \theta)}{p(X)} \\
\]</span></p>
<p>Given a statistical model, the theorem can be used to infer
probabilities of the values of the model parameters <span class="math inline">\(\theta\)</span> conditional on the available data
<span class="math inline">\(X\)</span>. These probabilities are
quantified by the <em>posterior distribution</em> <span class="math inline">\(p(\theta | X)\)</span>. The <em>prior
distribution</em> <span class="math inline">\(p(\theta)\)</span> is used
to impose beliefs about <span class="math inline">\(\theta\)</span>
without taking the data into account. The <em>likelihood function</em>
<span class="math inline">\(p(X | \theta)\)</span> gives the probability
of the data conditional on <span class="math inline">\(\theta\)</span>
and specifies the effect of data on the posterior. The denominator on
the right-hand side <span class="math inline">\(p(X)\)</span> is called
the marginal probability, which is often practically impossible to
compute, and usually the proportional version of the Bayes’ formula is
used:</p>
<p><span class="math display">\[
p(\theta | X) \propto p(\theta)  p(X | \theta).
\]</span></p>
<p>The proportional Bayes’ formula produces an unnormalized posterior
distribution which can then be normalized to access the normalized
posterior.</p>
<div class="section level3">
<h3 id="example-handedness">Example: handedness<a class="anchor" aria-label="anchor" href="#example-handedness"></a>
</h3>
<p>Let’s illustrate the use of the Bayes’ theorem with an example.</p>
<p>Assume we are trying to estimate the prevalence of left-handedness in
humans, based on a sample of <span class="math inline">\(N=50\)</span>
students, out of which <span class="math inline">\(x=7\)</span> are
left-handed and 43 right-handed.</p>
<p>The outcome is binary and the students are assumed to be independent
(e.g. no twins), so the binomial distribution is the appropriate choice
for likelihood:</p>
<p><span class="math display">\[
p(X|\theta) = Bin(7 | 50, \theta).
\]</span></p>
<p>Without further justification, we’ll choose <span class="math inline">\(p(\theta) = Beta(\theta |1, 10)\)</span> as the
prior distribution, so the unnormalized posterior distribution is</p>
<p><span class="math display">\[
p(\theta | X) = Bin(7 | 50, \theta) \cdot Beta(\theta | 1, 10).
\]</span></p>
<p>Below, we’ll plot these functions. Likelihood has been normalized for
better illustration.</p>
<figure><img src="fig/bayesian-statistics-rendered-unnamed-chunk-2-1.png" width="100%" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
</section><section id="communicating-posterior-information"><h2 class="section-heading">Communicating posterior information<a class="anchor" aria-label="anchor" href="#communicating-posterior-information"></a>
</h2>
<hr class="half-width">
<p>The posterior distribution <span class="math inline">\(p(\theta |
X)\)</span> is the target of Bayesian data analysis. It contains all the
information about <span class="math inline">\(\theta\)</span> given the
data, chosen model, and the prior beliefs. However, a distribution in
and of itself is usually not very informative, especially if it has an
even moderately exotic analytical form. The more common scenario is,
that the analytical form is not known.</p>
<p>Simply by looking at the figure above, we can get some understanding
of the probable values for <span class="math inline">\(\theta\)</span>.
Value between 0 and 0.25 seem to be the most probable and there
practically no posterior mass for values close to 1.</p>
<p>However, in order to communicate posterior information, we need some
means of quantifying the information.</p>
<p>Two types of estimates are commonly used: point estimates, such as
posterior mean, mode and variance, and posterior intervals, which give
probabilities for ranges of values.</p>
<p>Two types of posterior intervals are of interest on this course:</p>
<ol style="list-style-type: decimal">
<li><p><em>Credible intervals</em> (CIs) are intervals that leave equal
posterior mass below and above it. They are computed as posterior
quantiles. For example, the 90% CI would be between the 5% and 95%
quantiles.</p></li>
<li><p><em>Defined boundary intervals</em> which are computed as the
posterior mass for part of the parameter space, and can quantify the
probability for a given parameter condition. For instance, we might be
interested in the posterior probability that <span class="math inline">\(\theta &gt; 0\)</span>, <span class="math inline">\(0&lt;\theta&lt;0.5\)</span>, or <span class="math inline">\(\theta&lt;0\)</span> or <span class="math inline">\(\theta &gt; 0.5\)</span>. These probabilities can
be computed by integrating the posterior over the corresponding
sets.</p></li>
</ol>
<p>The following figures illustrate selected posterior intervals.</p>
<figure><img src="fig/bayesian-statistics-rendered-unnamed-chunk-3-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure></section><section id="grid-approximation"><h2 class="section-heading">Grid approximation<a class="anchor" aria-label="anchor" href="#grid-approximation"></a>
</h2>
<hr class="half-width">
<p>Specifying probabilistic model can be simple but a common bottle-neck
in Bayesian data analysis is model fitting. Later in the course we will
start using Stan which is a state-of-the-art method for approximating
the posterior. However, now we’ll use the grid approximation. This
approximation is based on computing the unnormalized posterior
distribution at a grid of evenly spaced values of the parameter space,
and can be specified as follows:</p>
<ol style="list-style-type: decimal">
<li>Define a grid of parameter values</li>
<li>Compute prior and likelihood on the grid</li>
<li>Multiply to get unnormalized posterior</li>
<li>Normalize</li>
</ol>
<p>Now, we’ll implement the grid approximation for the handedness
example in R.</p>
<div class="section level3">
<h3 id="example-binomial-model-with-the-grid-approximation">Example: Binomial model with the grid approximation<a class="anchor" aria-label="anchor" href="#example-binomial-model-with-the-grid-approximation"></a>
</h3>
<p>First, define the data variables and the grid of parameter values</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Sample size</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">50</span></span>
<span></span>
<span><span class="co"># 7/50 are left-handed</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span></span>
<span><span class="co"># Define a grid of points in the interval [0, 1], with 0.01 interval</span></span>
<span><span class="va">delta</span> <span class="op">&lt;-</span> <span class="fl">0.01</span></span>
<span><span class="va">theta_grid</span> <span class="op">&lt;-</span> <span class="fu">seq</span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, by <span class="op">=</span> <span class="va">delta</span><span class="op">)</span></span></code></pre>
</div>
<p>Computing the values of the likelihood, prior and unnormalized
posterior is straight-forward. These commands use vectorization.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu">dbinom</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, size <span class="op">=</span> <span class="va">N</span>, prob <span class="op">=</span> <span class="va">theta_grid</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu">dbeta</span><span class="op">(</span><span class="va">theta_grid</span>, <span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span><span class="op">*</span><span class="va">prior</span></span></code></pre>
</div>
<p>Next, the posterior needs to be normalized. In practice, this means
dividing the values with the area under the unnormalized posterior. The
area is computed with the integral <span class="math inline">\(\int_0^1
p(\theta | X)_{\text{unnormalized}}d\theta\)</span>, which is the
discrete scenario is simply <span class="math inline">\(\sum_{\text{grid}} p(\theta |
X)_{\text{unnormalized}} \cdot \delta,\)</span> where <span class="math inline">\(\delta\)</span> is the grid interval.</p>
<p>Notice that the likelihood function is not a distribution in terms of
the parameter <span class="math inline">\(\theta\)</span>, so it doesn’t
sum to one. Below, we normalize it too so comparison with prior and
posterior is easier.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># normalize </span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">posterior</span><span class="op">/</span><span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="va">likelihood</span><span class="op">/</span><span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="va">likelihood</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span></span></code></pre>
</div>
<p>Finally, we can plot these functions</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Make data frame</span></span>
<span><span class="va">df_hand</span> <span class="op">&lt;-</span> <span class="fu">data.frame</span><span class="op">(</span>theta <span class="op">=</span> <span class="va">theta_grid</span>, <span class="va">likelihood</span>, <span class="va">prior</span>, <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># wide to long format</span></span>
<span><span class="va">df_l</span> <span class="op">&lt;-</span> <span class="va">df_hand</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"Function"</span>, value <span class="op">=</span> <span class="st">"value"</span>, <span class="op">-</span><span class="va">theta</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot</span></span>
<span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">df_l</span>, </span>
<span>       <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="va">value</span>, color <span class="op">=</span> <span class="va">Function</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_color_grafify</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p1</span></span></code></pre>
</div>
<figure><img src="fig/bayesian-statistics-rendered-unnamed-chunk-7-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<p>Play around with different priors and examine effect on the
posterior.</p>
<p>Would it be fair to say that the posterior is a compromise between
data (likelihood) and prior?</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="summarizing-posterior-information">Summarizing posterior information<a class="anchor" aria-label="anchor" href="#summarizing-posterior-information"></a>
</h3>
<p>Next, we’ll learn how to compute the point estimates and posterior
intervals based on the grid approximation.</p>
<p>Computing posterior mean and variance is based on the definition of
these statistics for continuous variables. Mean is defined as <span class="math inline">\(\int \theta \cdot p(\theta | X) d\theta\)</span>
and can be computed using discrete integration: <span class="math inline">\(\sum_{\text{grid}} \theta \cdot p(\theta | X)
\cdot \delta\)</span>. Variance can be computed similarly. The mode or
MAP estimate is simply the grid value where the posterior is
maximized.</p>
<p>In R, these statistics can be computed as follows:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">data.frame</span><span class="op">(</span>Estimate <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"Mode"</span>, <span class="st">"Mean"</span>, <span class="st">"Variance"</span><span class="op">)</span>, </span>
<span>           Value <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">df_hand</span><span class="op">[</span><span class="fu">which.max</span><span class="op">(</span><span class="va">df_hand</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, <span class="st">"theta"</span><span class="op">]</span>,</span>
<span>                     <span class="fu">sum</span><span class="op">(</span><span class="va">df_hand</span><span class="op">$</span><span class="va">theta</span><span class="op">*</span><span class="va">df_hand</span><span class="op">$</span><span class="va">posterior</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span>, </span>
<span>                     <span class="fu">sum</span><span class="op">(</span><span class="va">df_hand</span><span class="op">$</span><span class="va">theta</span><span class="op">^</span><span class="fl">2</span><span class="op">*</span><span class="va">df_hand</span><span class="op">$</span><span class="va">posterior</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span> <span class="op">-</span></span>
<span>                       <span class="fu">sum</span><span class="op">(</span><span class="va">df_hand</span><span class="op">$</span><span class="va">theta</span><span class="op">*</span><span class="va">df_hand</span><span class="op">$</span><span class="va">posterior</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>  Estimate       Value
1     Mode 0.120000000
2     Mean 0.131147540
3 Variance 0.001837869</code></pre>
</div>
<p>Posterior intervals are also relatively easy to compute.</p>
<p>Finding the quantiles used to determine CIs is based on the
cumulative distribution function <span class="math inline">\(F(x) =
\int_{\infty}^{x}p(x) dx\)</span>. The locations where the <span class="math inline">\(F(x) = 0.05\)</span> and <span class="math inline">\(F(x) = 0.95\)</span> define the 90% CIs.</p>
<p>Probabilities for certain parameter values are computed simply by
integrating over the appropriate set. For instance, <span class="math inline">\(Pr(\theta &lt; 0.1) = \int_0^{0.1} p(\theta | X)
d\theta\)</span></p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge1"></a>
</h3>
<div class="callout-content">
<p>Compute the 90% CIs and the probability <span class="math inline">\(Pr(\theta &lt; 0.1)\)</span> for the handedness
example.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Quantiles</span></span>
<span><span class="va">q5</span> <span class="op">&lt;-</span> <span class="va">theta_grid</span><span class="op">[</span><span class="fu">which.max</span><span class="op">(</span><span class="fu">cumsum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span> <span class="op">&gt;</span> <span class="fl">0.05</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">q95</span> <span class="op">&lt;-</span> <span class="va">theta_grid</span><span class="op">[</span><span class="fu">which.min</span><span class="op">(</span><span class="fu">cumsum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span> <span class="op">&lt;</span> <span class="fl">0.95</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Pr(theta &lt; 0.1)</span></span>
<span><span class="va">Pr_theta_under_0.1</span> <span class="op">&lt;-</span> <span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">[</span><span class="va">theta_grid</span> <span class="op">&lt;</span> <span class="fl">0.1</span><span class="op">]</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">paste0</span><span class="op">(</span><span class="st">"90% CI = ("</span>, <span class="va">q5</span>,<span class="st">","</span>, <span class="va">q95</span>,<span class="st">")"</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] "90% CI = (0.07,0.21)"</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">print</span><span class="op">(</span><span class="fu">paste0</span><span class="op">(</span><span class="st">"Pr(theta &lt; 0.1) = "</span>, <span class="va">Pr_theta_under_0.1</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] "Pr(theta &lt; 0.1) = 0.20659405208227"</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="example-gamma-model">Example: Gamma model<a class="anchor" aria-label="anchor" href="#example-gamma-model"></a>
</h3>
<p>Assume the following data points were generated independently from a
<span class="math inline">\(\Gamma(\alpha, \beta)\)</span> distribution
with unknown shape <span class="math inline">\(\alpha\)</span> and rate
<span class="math inline">\(\beta\)</span>:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">c</span><span class="op">(</span><span class="fl">0.34</span>, <span class="fl">0.2</span>, <span class="fl">0.22</span>, <span class="fl">0.77</span>, <span class="fl">0.46</span>, <span class="fl">0.73</span>, <span class="fl">0.24</span>, <span class="fl">0.66</span>, <span class="fl">0.64</span><span class="op">)</span></span></code></pre>
</div>
<p>Let’s estimate the unknown parameters using the grid
approximation.</p>
<p>Similarly as before, we’ll define a grid of points for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Now, since our parameter space is
2-dimensional, the grid is defined at all pairwise combinations of the
individual grids.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">delta</span> <span class="op">&lt;-</span> <span class="fl">0.1</span></span>
<span><span class="va">alpha_grid</span> <span class="op">&lt;-</span> <span class="fu">seq</span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0.01</span>, to <span class="op">=</span> <span class="fl">15</span>, by <span class="op">=</span> <span class="va">delta</span><span class="op">)</span></span>
<span><span class="va">beta_grid</span> <span class="op">&lt;-</span> <span class="fu">seq</span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0.01</span>, to <span class="op">=</span> <span class="fl">25</span>, by <span class="op">=</span> <span class="va">delta</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Get pairwise combinations</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">expand.grid</span><span class="op">(</span>alpha <span class="op">=</span> <span class="va">alpha_grid</span>, beta <span class="op">=</span> <span class="va">beta_grid</span><span class="op">)</span></span></code></pre>
</div>
<p>Next, we’ll compute the likelihood which is the product of the
likelihoods of individual observations.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Loop over all alpha, beta combinations</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">df</span><span class="op">[</span><span class="va">i</span>, <span class="st">"likelihood"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">prod</span><span class="op">(</span></span>
<span>    <span class="fu">dgamma</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>,</span>
<span>           shape <span class="op">=</span> <span class="va">df</span><span class="op">[</span><span class="va">i</span>, <span class="st">"alpha"</span><span class="op">]</span>,</span>
<span>           rate <span class="op">=</span> <span class="va">df</span><span class="op">[</span><span class="va">i</span>, <span class="st">"beta"</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Next, we’ll add priors for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. They can only be positive which
should be reflected in the prior. A conjugate prior for the Gamma
likelihood <a href="https://en.wikipedia.org/wiki/Gamma_distribution#Bayesian_inference" class="external-link">exists</a>
but we’ll use simple <span class="math inline">\(\Gamma\)</span> priors
with large variance.</p>
<p>Notice, that normalizing the posterior now requires integrating over
both dimensions, hence the <span class="math inline">\(\delta^2\)</span>
below.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Priors: alpha, beta ~ Gamma(2, .1)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">df</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>prior <span class="op">=</span> <span class="fu">dgamma</span><span class="op">(</span>x <span class="op">=</span> <span class="va">alpha</span>, <span class="fl">2</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">*</span><span class="fu">dgamma</span><span class="op">(</span>x <span class="op">=</span> <span class="va">beta</span>, <span class="fl">2</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Posterior</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">df</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>posterior <span class="op">=</span> <span class="va">prior</span><span class="op">*</span><span class="va">likelihood</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>posterior <span class="op">=</span> <span class="va">posterior</span><span class="op">/</span><span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="co"># normalize</span></span>
<span></span>
<span></span>
<span><span class="co"># Plot</span></span>
<span><span class="va">p_joint_posterior</span> <span class="op">&lt;-</span> <span class="va">df</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_tile</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">alpha</span>, y <span class="op">=</span> <span class="va">beta</span>, fill <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">scale_fill_gradientn</span><span class="op">(</span>colours <span class="op">=</span> <span class="fu">rainbow</span><span class="op">(</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_joint_posterior</span></span></code></pre>
</div>
<figure><img src="fig/bayesian-statistics-rendered-unnamed-chunk-13-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Next, we’ll compute the MAP, which is a point in the 2-dimensional
parameter space.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df</span><span class="op">[</span><span class="fu">which.max</span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"alpha"</span>, <span class="st">"beta"</span><span class="op">)</span><span class="op">]</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>      alpha beta
14898  4.71 9.91</code></pre>
</div>
<p>However, often in addition to the parameters of interest, the model
contains parameters we are not interested. For instance, we could only
interested in the value of <span class="math inline">\(\alpha\)</span>,
which would make <span class="math inline">\(\beta\)</span> a ‘nuisance’
parameter. Nuisance parameters are part of the full (‘joint’) posterior,
but they can be discarded by integrating the joint posterior over these
parameters (see BDA3: p.63 for details). A posterior integrated over
some parameters is called a marginal posterior.</p>
<p>Let’s now compute the marginal posterior for <span class="math inline">\(\alpha\)</span> by integrating over <span class="math inline">\(\beta\)</span>. Intuitively it can be helpful to
think of marginalization as a process where all of the joint posterior
mass is drawn towards the <span class="math inline">\(\alpha\)</span>
axis, as if drawn by a gravitational force.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get marginal posterior for alpha</span></span>
<span><span class="va">alpha_posterior</span> <span class="op">&lt;-</span> <span class="va">df</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">summarize</span><span class="op">(</span>posterior <span class="op">=</span> <span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>posterior <span class="op">=</span> <span class="va">posterior</span><span class="op">/</span><span class="op">(</span><span class="fu">sum</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">*</span><span class="va">delta</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">p_alpha_posterior</span> <span class="op">&lt;-</span> <span class="va">alpha_posterior</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">alpha</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>, </span>
<span>            color <span class="op">=</span> <span class="va">posterior_color</span>, </span>
<span>            linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_alpha_posterior</span></span></code></pre>
</div>
<figure><img src="fig/bayesian-statistics-rendered-unnamed-chunk-15-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge2"></a>
</h3>
<div class="callout-content">
<p>Does the MAP of the joint posterior of <span class="math inline">\(\theta = (\alpha, \beta)\)</span> correspond to
the MAPs of the marginal posteriors of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>No. Why?</p>
</div>
</div>
</div>
</div>
</div>
</section><section id="working-with-samples"><h2 class="section-heading">Working with samples<a class="anchor" aria-label="anchor" href="#working-with-samples"></a>
</h2>
<hr class="half-width">
<p>The main limitation of the grid approximation method is that it
becomes impractical for models with even a moderate number of
parameters. The reason is that the number of computations grows as <span class="math inline">\(O \{ \Delta^p \}\)</span> where <span class="math inline">\(\Delta\)</span> is the number of grid points per
model parameter and <span class="math inline">\(p\)</span> the number of
parameters. This quickly becomes prohibitive, and the grid approximation
is seldom used in practice. The standard approach to fitting Bayesian
models is to draw samples from the posterior with Markov chain Monte
Carlo (MCMC) methods. These are the topic of a later episode but we’ll
anticipate this now by studying how posterior summaries can be computed
based on samples.</p>
<p>Let’s use the Beta-binomial model (beta prior, binomial likelihood)
of the handedness example. It is an example of a model for which the
posterior can be computed analytically. Given a prior <span class="math inline">\(Beta(\alpha, \beta)\)</span> and likelihood <span class="math inline">\(Bin(x | N, \theta)\)</span>, the posterior is
<span class="math display">\[p(\theta | X) = Beta(\alpha + x, \beta + N
- x).\]</span> Let’s simulate <span class="math inline">\(n =
1000\)</span> samples from this posterior using the handedness data:</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">theta_samples</span> <span class="op">&lt;-</span> <span class="fu">rbeta</span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span> <span class="op">+</span> <span class="fl">7</span>, <span class="fl">10</span> <span class="op">+</span> <span class="fl">50</span> <span class="op">-</span> <span class="fl">7</span><span class="op">)</span></span></code></pre>
</div>
<p>Plotting a histogram of these samples against the grid approximation
displays that these are indeed approximating the same distribution
<img src="fig/bayesian-statistics-rendered-unnamed-chunk-17-1.png" style="display: block; margin: auto;" class="figure"></p>
<p>Computing posterior summaries from samples is easy. The posterior
mean and variance are computed simply by taking the mean and variance of
the samples, respectively. Posterior intervals are equally easy to
compute, 90% CI is recovered from the appropriate quantiles and the
probabilities of certain intervals are simply the proportion of samples
in the interval.</p>
<div id="discussion2" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#discussion2"></a>
</h3>
<div class="callout-content">
<p>Compute the posterior mean, variance, 90% CI and <span class="math inline">\(Pr(\theta &gt; 0.1)\)</span> using the generated
samples.</p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Likelihood determines the probability of data conditional on the
model parameters</li>
<li>Prior encodes beliefs about the model parameters without taking data
into account</li>
<li>Posterior quantifies the probability of parameter values conditional
on the data.</li>
<li>Posterior is a compromise between the data and prior. The less data
available, the bigger the effect of the prior.</li>
<li>The grid approximation is a way to infer the (approximate) posterior
distribution.</li>
<li>Posterior information can be summarized with point estimates and
posterior intervals.</li>
<li>Marginal posterior is accessed by integrating over nuisance
parameters.</li>
<li>Usually, Bayesian models are fit using methods that produce samples
from the posterior.</li>
</ul>
</div>
</div>
</div>
</section><section id="reading"><h2 class="section-heading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li>Bayesian Data Analysis (3rd ed.): Ch. 1-3</li>
<li>Statistical Rethinking (2nd ed.): Ch. 1-3</li>
<li>Bayes Rules!: Ch. 1-6</li>
</ul>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 --></section></section><section id="aio-stan"><p>Content from <a href="stan.html">Stan</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/stan.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is Stan?</li>
<li>How to efficiently generate samples from a posterior?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Install Stan and get it running</li>
<li>Learn how to specify models in Stan</li>
<li>How to generate samples with Stan</li>
<li>How to process samples generated with Stan</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Stan is a programming language that can be used to generate samples
from the posterior distribution. Stan does this by utilizing a Markov
Chain Monte Carlo (MCMC) algorithm, and more specifically a variant of
it called Hamiltonian Monte Carlo.</p>
<p>The next episode is devoted to MCMC but in this one we will learn how
to run it using Stan.</p>
<p>Follow the instruction at <a href="https://mc-stan.org/users/interfaces/" class="external-link uri">https://mc-stan.org/users/interfaces/</a> to install Stan on
your local computer.</p>
<p>While Stan makes model specifying a statistical model relatively easy
and automates the sampling, the bottle-neck of fitting is not fully
removed. In theory, MCMC methods will always converge to the target
distribution (posterior for us). However, in practice, convergence
issues can arise. Luckily‚ Stan produces warnings automatically which
can be used in assessing model convergence.</p>
<section id="basic-program-structure"><h2 class="section-heading">Basic program structure<a class="anchor" aria-label="anchor" href="#basic-program-structure"></a>
</h2>
<hr class="half-width">
<p>A Stan program is structured into several blocks that define the
statistical model. A Stan program typically (but not necessarily) will
include the following blocks:</p>
<ol style="list-style-type: decimal">
<li><p>Data block: This block is used to declare the input data fed into
the model. It specifies the types and dimensions of the data variables
used in the model.</p></li>
<li><p>Parameters block: In this block, the model’s parameters are
declared.</p></li>
<li><p>Model block: The likelihood and prior distributions are included
here in the form of sampling statements.</p></li>
</ol>
<p>It is recommended that you specify the Stan programs in a separate
text files and call it from R (or other supported interface). The
extension of the file must be <code>.stan</code>.</p>
</section><section id="example-1-beta-binomial-model"><h2 class="section-heading">Example 1: Beta-binomial model<a class="anchor" aria-label="anchor" href="#example-1-beta-binomial-model"></a>
</h2>
<hr class="half-width">
<p>The following Stan program specifies the Beta-binomial model. There
program consists of data, parameters, and model blocks.</p>
<p>The data variables are the total sample size <span class="math inline">\(N\)</span> and the outcome of a binary variable
(coin flip, handedness etc.). The declared data type in <code>int</code>
for integer and the variables have a lower bound 1 and 0 for <span class="math inline">\(N\)</span> and <span class="math inline">\(x\)</span>, respectively. Notice that each line
ends with a semicolon.</p>
<p>In the parameters block we declare <span class="math inline">\(\theta\)</span>, the probability for a success.
Since this parameter is a probability, it is restricted between 0 and
1.</p>
<p>In the model block, the likelihood is specified with the sampling
statement <code>x ~ binomial(N, theta)</code>. This line includes the
binomial distribution <span class="math inline">\(Bin(x | N,
theta)\)</span> in the target distribution. The prior could be set
similarly but omitting it implies a uniform prior.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span>{</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N; </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; x; </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">parameters</span>{</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; theta;</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">model</span>{</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Likelihood</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    x ~ binomial(N, theta);</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Uniform prior for theta</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  }</span></code></pre>
</div>
<p>Once the Stan program has been saved we need to compile it. In R,
this is done by running</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">binomial_model</span> <span class="op">&lt;-</span> <span class="fu">stan_model</span><span class="op">(</span><span class="st">"binomial_model.stan"</span><span class="op">)</span></span></code></pre>
</div>
<p>Once the program has been compiled, it can be used to generate the
posterior samples with the function <code>sampling()</code>. The data
needs to be defined as a list. While running, Stan prints progress.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">binom_data</span> <span class="op">&lt;-</span> <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="fl">50</span>, x <span class="op">=</span> <span class="fl">7</span><span class="op">)</span></span>
<span></span>
<span><span class="va">binom_samples</span> <span class="op">&lt;-</span> <span class="fu">sampling</span><span class="op">(</span><span class="va">binomial_model</span>, <span class="va">binom_data</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 6e-06 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.004 seconds (Warm-up)
Chain 1:                0.004 seconds (Sampling)
Chain 1:                0.008 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.004 seconds (Warm-up)
Chain 2:                0.003 seconds (Sampling)
Chain 2:                0.007 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 1e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.004 seconds (Warm-up)
Chain 3:                0.003 seconds (Sampling)
Chain 3:                0.007 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 1e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.004 seconds (Warm-up)
Chain 4:                0.003 seconds (Sampling)
Chain 4:                0.007 seconds (Total)
Chain 4: </code></pre>
</div>
<p>With the default setting Stan runs 4 MCMC chains with 2000 iterations
(more about this in Episode 5 on MCMC). Running
<code>binom_samples</code> prints a summary for the model parameter
<span class="math inline">\(p\)</span> allowing quick reviewing of
result.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">binom_samples</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Inference for Stan model: anon_model.
4 chains, each with iter=2000; warmup=1000; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
theta   0.15    0.00 0.05   0.07   0.12   0.15   0.18   0.25  1377    1
lp__  -22.81    0.02 0.70 -24.78 -22.96 -22.54 -22.38 -22.33  1416    1

Samples were drawn using NUTS(diag_e) at Tue Jan 16 07:57:22 2024.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).</code></pre>
</div>
<p>This summary can also be accessed as a matrix with
<code>summary(binom_samples)$summary</code>.</p>
<p>Often, however, it is necessary to work with the individual samples.
These can be extracted as follows:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p_samples</span> <span class="op">&lt;-</span> <span class="fu">extract</span><span class="op">(</span><span class="va">binom_samples</span>, <span class="st">"theta"</span><span class="op">)</span><span class="op">[[</span><span class="st">"theta"</span><span class="op">]</span><span class="op">]</span></span></code></pre>
</div>
<p>Now we can use the methods presented in the previous Episode to
compute posterior summaries, credible intervals and to generate
figures.</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge1"></a>
</h3>
<div class="callout-content">
<p>Compute the 95% credible intervals for the samples drawn with Stan.
What is the probability that <span class="math inline">\(theta \in
(0.05, 0.15)\)</span>? Plot a histogram of the posterior samples.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">CI95</span> <span class="op">&lt;-</span> <span class="fu">quantile</span><span class="op">(</span><span class="va">theta_samples</span>, probs <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">ERROR<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="error" tabindex="0"><code>Error in eval(expr, envir, enclos): object 'theta_samples' not found</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">theta_between_0.05_0.15</span> <span class="op">&lt;-</span> <span class="fu">mean</span><span class="op">(</span><span class="va">theta_samples</span><span class="op">&gt;</span><span class="fl">0.05</span> <span class="op">&amp;</span> <span class="va">theta_samples</span><span class="op">&lt;</span><span class="fl">0.15</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">ERROR<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="error" tabindex="0"><code>Error in eval(expr, envir, enclos): object 'theta_samples' not found</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">data.frame</span><span class="op">(</span>theta <span class="op">=</span> <span class="va">theta_samples</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_cartesian</span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">ERROR<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="error" tabindex="0"><code>Error in eval(expr, envir, enclos): object 'theta_samples' not found</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">print</span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">ERROR<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="error" tabindex="0"><code>Error in eval(expr, envir, enclos): object 'p' not found</code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge2"></a>
</h3>
<div class="callout-content">
<p>Try modifying the Stan program so that you add a <span class="math inline">\(Beta(\alpha, \beta)\)</span> prior for <span class="math inline">\(\theta\)</span>.</p>
<p>Can you modify the Stan program further so that you can set the
hyperparameters <span class="math inline">\(\alpha, \beta\)</span> as
part of the data? What is the benefit of using this approach?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>If the data block is modified so that it declares the hyperparameters
as data (e.g. <code>real&lt;lower=0&gt; alpha;</code>), it enables
setting the hyperparameter values as part of data. This way
hyperparameters can be changed without modifying the Stan file.</p>
</div>
</div>
</div>
</div>
</section><section id="additional-stan-blocks"><h2 class="section-heading">Additional Stan blocks<a class="anchor" aria-label="anchor" href="#additional-stan-blocks"></a>
</h2>
<hr class="half-width">
<p>Functions For user-defined functions Must be the first block!</p>
<p>Transformed data Transformations of the data variables</p>
<p>Transformed parameters Transformations of the parameters Remember
Jacobian in the model block!</p>
<p>Generated quantities Define quantities based on data and model
parameters Produces a posterior</p>
</section><section id="stan-shortcuts"><h2 class="section-heading">Stan shortcuts<a class="anchor" aria-label="anchor" href="#stan-shortcuts"></a>
</h2>
<hr class="half-width">
<ul>
<li>Modeling: rstanarm, brms; Plotting: bayesplot; Summaries and
convergence: ShinyStan</li>
<li>Syntax similar to standard R
<ul>
<li>Linear model: fit &lt;- stan_glm(y ~ x, data = df, family =
gaussian)</li>
</ul>
</li>
</ul>
<p>We will not use these! We will learn to Write Stan programs from
scratch → flexibility Access and manipulate the output Generate
visualization</p>
</section><section id="example-2-normal-model"><h2 class="section-heading">Example 2: normal model<a class="anchor" aria-label="anchor" href="#example-2-normal-model"></a>
</h2>
<hr class="half-width">
<p>Next, let’s implement the normal model in Stan. First generate some
data with unknown mean and standard deviation parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span></p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Sample size</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">99</span></span>
<span></span>
<span><span class="co"># Generate data with unknown parameters</span></span>
<span><span class="va">unknown_sigma</span> <span class="op">&lt;-</span> <span class="fu">runif</span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">unknown_mu</span> <span class="op">&lt;-</span> <span class="fu">runif</span><span class="op">(</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">rnorm</span><span class="op">(</span>n <span class="op">=</span> <span class="va">N</span>,</span>
<span>           mean <span class="op">=</span> <span class="va">unknown_mu</span>,</span>
<span>           sd <span class="op">=</span> <span class="va">unknown_sigma</span><span class="op">)</span> </span></code></pre>
</div>
<p>Then the stan program, which the following piece of code stores as
<code>normal_model</code>.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] X;</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> mu;</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">// likelihood is vectorized!</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  X ~ normal(mu, sigma);</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Priors</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>  mu ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>  sigma ~ gamma(<span class="dv">2</span>, <span class="dv">1</span>);</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>}</span></code></pre>
</div>
<p>Notice that the likelihood in the model block is vectorized.
Alternatively, one could write a for loop that samples each data point
individually from the likelihood:
<code>X[i] ~normal(\mu, \sigma)</code>. This would be an inefficient way
of implementing the likelihood function and vectorization is
recommended. However, when writing complex models it may be useful to
initially write the model in an unvectorized format so debugging is
easier.</p>
<p>Let’s again fit the model on the data</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Call Stan</span></span>
<span><span class="va">normal_samples</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">sampling</span><span class="op">(</span><span class="va">normal_model</span>, </span>
<span>                                  <span class="fu">list</span><span class="op">(</span>N <span class="op">=</span> <span class="va">N</span>, X <span class="op">=</span> <span class="va">X</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 4e-06 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.007 seconds (Warm-up)
Chain 1:                0.007 seconds (Sampling)
Chain 1:                0.014 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.007 seconds (Warm-up)
Chain 2:                0.006 seconds (Sampling)
Chain 2:                0.013 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 2e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.007 seconds (Warm-up)
Chain 3:                0.007 seconds (Sampling)
Chain 3:                0.014 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 1e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.007 seconds (Warm-up)
Chain 4:                0.006 seconds (Sampling)
Chain 4:                0.013 seconds (Total)
Chain 4: </code></pre>
</div>
<p>and plot the posterior</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract parameter samples</span></span>
<span><span class="va">par_samples</span> <span class="op">&lt;-</span> <span class="fu">extract</span><span class="op">(</span><span class="va">normal_samples</span>, <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">cbind</span>, <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">data.frame</span></span>
<span></span>
<span></span>
<span><span class="co"># Full posterior</span></span>
<span><span class="va">p_posterior</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">par_samples</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">unknown_mu</span>, y <span class="op">=</span> <span class="va">unknown_sigma</span><span class="op">)</span>,</span>
<span>             color <span class="op">=</span> <span class="st">"red"</span>, size <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Marginal posteriors</span></span>
<span><span class="va">p_marginals</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">par_samples</span> <span class="op">%&gt;%</span> <span class="va">gather</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">value</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">40</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">data.frame</span><span class="op">(</span>key <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span>, </span>
<span>                               value <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">unknown_mu</span>, <span class="va">unknown_sigma</span><span class="op">)</span><span class="op">)</span>, </span>
<span>             <span class="fu">aes</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">value</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">key</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu">cowplot</span><span class="fu">::</span><span class="fu">plot_grid</span><span class="op">(</span><span class="va">p_posterior</span>, <span class="va">p_marginals</span>,</span>
<span>                  ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="fig/stan-rendered-unnamed-chunk-11-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure></section><section id="example-3-linear-regression"><h2 class="section-heading">Example 3: Linear regression<a class="anchor" aria-label="anchor" href="#example-3-linear-regression"></a>
</h2>
<hr class="half-width"></section><section id="example-4-random-walk"><h2 class="section-heading">Example 4: Random walk<a class="anchor" aria-label="anchor" href="#example-4-random-walk"></a>
</h2>
<hr class="half-width">
<div id="challenge3" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge3"></a>
</h3>
<div class="callout-content">
<p>Write a Stan program for linear regression with one dependent
variable.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3">Show me the solution</h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N; <span class="co">// Sample size</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] x; <span class="co">// x-values</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] y; <span class="co">// y-values</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> alpha; <span class="co">// intercept</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta;  <span class="co">// slope</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma; <span class="co">// noise</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Likelihood</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>  y ~ normal(alpha + beta * x, sigma);</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Priors</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>  alpha ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>  beta ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>  sigma ~ gamma(<span class="dv">2</span>, <span class="dv">1</span>);</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>}</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="challenge4" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge4"></a>
</h3>
<div class="callout-content">
<p>Write a Stan program for linear regression with <span class="math inline">\(M\)</span> dependent variables.</p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4">Show me the solution</h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" aria-labelledby="headingSolution4" data-bs-parent="#accordionSolution4">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N; <span class="co">// Sample size</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; M; <span class="co">// Number of features</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N, M] x; <span class="co">// x-values</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] y; <span class="co">// y-values</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> alpha; <span class="co">// intercept</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[M] beta;  <span class="co">// slopes</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma; <span class="co">// noise</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Likelihood</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>  y ~ normal(alpha + x * beta, sigma);</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Priors</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>  alpha ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>  beta ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>  sigma ~ gamma(<span class="dv">2</span>, <span class="dv">1</span>);</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>}</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="callout1" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout1"></a>
</h3>
<div class="callout-content">
<ul>
<li><p>With Stan, you can fit model that have continuous parameters.
Models with discrete parameters such as most classification models are
typically impossible to fit, although some workarounds have been
implemented.</p></li>
<li><p>Bayesplot, rstanarm, brms</p></li>
</ul>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Stan is…</li>
</ul>
</div>
</div>
</div>
</section><section id="resources"><h2 class="section-heading">Resources<a class="anchor" aria-label="anchor" href="#resources"></a>
</h2>
<hr class="half-width">
<ul>
<li>Official release paper <a href="https://www.jstatsoft.org/article/view/v076i01" class="external-link uri">https://www.jstatsoft.org/article/view/v076i01</a>
</li>
<li>User’s guide <a href="https://mc-stan.org/docs/2_18/stan-users-guide/" class="external-link uri">https://mc-stan.org/docs/2_18/stan-users-guide/</a>
</li>
<li>Function’s reference <a href="https://mc-stan.org/docs/functions-reference/" class="external-link uri">https://mc-stan.org/docs/functions-reference/</a>
</li>
<li>Reference manual <a href="https://mc-stan.org/docs/reference-manual/" class="external-link uri">https://mc-stan.org/docs/reference-manual/</a>
</li>
<li>Stan forum <a href="https://discourse.mc-stan.org" class="external-link uri">https://discourse.mc-stan.org</a>
</li>
<li>Case studies <a href="https://mc-stan.org/users/documentation/case-studies" class="external-link uri">https://mc-stan.org/users/documentation/case-studies</a>
</li>
</ul></section><section id="reading"><h2 class="section-heading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li>BDA3: Ch. 12.6, Appendix C</li>
<li>Bayes Rules!: Ch. 6.2</li>
</ul>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 --></section></section><section id="aio-mcmc"><p>Content from <a href="mcmc.html">MCMC</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/mcmc.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is MCMC?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li><p>Idea behind MCMC</p></li>
<li>
<p>Learn how to</p>
<ul>
<li>assess convergence</li>
<li>implement MCMC</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Computing the posterior analytically poses an insurmountable
challenge in the general case. Even if we were aware of the analytical
form, marginalizing it to recover posteriors for the individual model
parameters would still be difficult. In Episode 3, we saw that drawing
conclusions about the inference could be achieved relatively easily by
working on samples from the posterior distribution. However, obtaining
such samples from the posterior distribution is a non-trivial task,
unless the analytical posterior is known. In this episode, we will delve
into Markov chain Monte Carlo methods (MCMC) that are the most
extensively employed solution for generating these samples.</p>
<section id="metropolis-hastings-algorithm"><h2 class="section-heading">Metropolis-Hastings algorithm<a class="anchor" aria-label="anchor" href="#metropolis-hastings-algorithm"></a>
</h2>
<hr class="half-width">
<p>MCMC methods draw samples from the posterior distribution by
constructing sequences (chains) of values in the parameter space that
ultimately converge to the posterior. While there are other variants of
MCMC, on this course we will mainly focus on the Metropolis-Hasting
algorithm outlined below</p>
<p>A chain starts at some initial value <span class="math inline">\(\theta^{0}\)</span>, which can be random or based
on some more informed criterion. The only precondition is that <span class="math inline">\(p(\theta^{0} | X) &gt; 0\)</span>. Then a
transition distribution <span class="math inline">\(T_i\)</span> is used
to generate a proposal for the subsequent value. An often-used solution
is the normal distribution centered at the current value, <span class="math inline">\(\theta^* \sim N(\theta^{i}, \sigma^2)\)</span>.
This is where the term “Markov chain” comes from, each element is
generated based on only the previous one.</p>
<p>Next, the generated proposal <span class="math inline">\(\theta^*\)</span> is either accepted or rejected.
If each proposal was accepted, the sequence would simply be a random
walk in the parameter space and would not approximate the posterior to
any degree. The rule that determines the acceptance should reflect this;
proposals towards higher posterior densities should be favored over
proposals toward low density areas. The solution is to compute the
ratio</p>
<p><span class="math display">\[r = \frac{p(\theta^* | X) / T_i(\theta^*
| \theta^{i})}{p(\theta^i | X) / T_i(\theta^{i} | \theta^{*})}.\]</span>
In situations where the transition density is symmetric, such as with
the normal distribution, <span class="math inline">\(r\)</span> reduces
simply to the ratio of the posterior values.</p>
<p>The next element in the chain is then chosen: with probability <span class="math inline">\(r\)</span> the chain moves to the proposal, <span class="math inline">\(\theta^{i+1} = \theta^*\)</span> and with
probability <span class="math inline">\(1-r\)</span> stays at the
current value, <span class="math inline">\(\theta^{i+1} =
\theta^{i}.\)</span></p>
<p>As the algorithm is ran long enough, convergence is guaranteed and
eventually the samples will start approximating the posterior
distribution.</p>
</section><section id="example"><h2 class="section-heading">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h2>
<hr class="half-width">
<p>Let’s look at the normal model and implement the Metropolis-Hastings
algorithm to sample the posterior. First we’ll simulate some data</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">mu_true</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">1.25</span></span>
<span><span class="va">sigma_true</span> <span class="op">&lt;-</span> <span class="fl">0.6</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">rnorm</span><span class="op">(</span><span class="va">N</span>, <span class="va">mu_true</span>, <span class="va">sigma_true</span><span class="op">)</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu">data.frame</span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span><span class="op">)</span>,</span>
<span>                 bins <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="fig/mcmc-rendered-unnamed-chunk-1-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Then, we’ll write some functions. Below, <code>pars</code> is of the
form <code>c(mu, sigma)</code>.</p>
<p>First the point-wise log likelihood. Remember that the likelihood is
the product of likelihoods for individual data points, which after a log
transformation turns into a sum.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">log_lh</span> <span class="op">&lt;-</span> <span class="fu">dnorm</span><span class="op">(</span><span class="va">X</span>,</span>
<span>                  mean <span class="op">=</span> <span class="va">pars</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,</span>
<span>                  sd <span class="op">=</span> <span class="va">pars</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,</span>
<span>                  log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="va">sum</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">log_lh</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Next, well define normal and Gamma priors as the priors. The log
posterior is the sum of log likelihood and log priors.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Priors: mu ~ normal, sigma ~ gamma  </span></span>
<span><span class="va">log_prior</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">log_mu_prior</span> <span class="op">&lt;-</span> <span class="fu">dnorm</span><span class="op">(</span>x <span class="op">=</span> <span class="va">pars</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,</span>
<span>                        mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                        log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">log_sigma_prior</span> <span class="op">&lt;-</span> <span class="fu">dgamma</span><span class="op">(</span>x <span class="op">=</span> <span class="va">pars</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,</span>
<span>                            shape <span class="op">=</span> <span class="fl">2</span>, rate <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                            log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">log_mu_prior</span> <span class="op">+</span> <span class="va">log_sigma_prior</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span><span class="va">log_posterior</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="fu">log_likelihood</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars</span><span class="op">)</span> <span class="op">+</span> <span class="fu">log_prior</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>The next function implements the transition density. We’ll use the
normal distribution for both parameters. However, as <span class="math inline">\(\sigma\)</span> cannot be negative, we’ll take the
absolute value to ensure positivity.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">generate_proposal</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">pars_old</span>, <span class="va">sd</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># proposal </span></span>
<span>  <span class="va">pars_new</span> <span class="op">&lt;-</span> <span class="fu">rnorm</span><span class="op">(</span><span class="fl">2</span>, mean <span class="op">=</span> <span class="va">pars_old</span>, sd <span class="op">=</span> <span class="va">sd</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># make sure sigma proposal &gt; 0</span></span>
<span>  <span class="va">pars_new</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">abs</span><span class="op">(</span><span class="va">pars_new</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">pars_new</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>The next function computes the acceptance ratio. Since the normal
distribution is a symmetric proposal, it suffices to compute the ratio
of the posteriors.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Acceptance probability</span></span>
<span><span class="va">get_ratio</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_old</span>, <span class="va">pars_new</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># Ratio of posteriors</span></span>
<span>  <span class="co"># No need to include ratio of proposal densities</span></span>
<span>  <span class="co"># because Gaussian density is symmetric</span></span>
<span>  <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">exp</span><span class="op">(</span><span class="fu">log_posterior</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_new</span><span class="op">)</span> <span class="op">-</span> <span class="fu">log_posterior</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_old</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">r</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Finally, here is the Metropolis-Hastings sampler for the normal
model.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">metropolis_sampler</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">X</span>, <span class="va">inits</span>, <span class="va">n_samples</span> <span class="op">=</span> <span class="fl">1000</span>, <span class="va">jump_sd</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">pars</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span>nrow <span class="op">=</span> <span class="va">n_samples</span>, ncol <span class="op">=</span> <span class="fu">length</span><span class="op">(</span><span class="va">inits</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">pars</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">inits</span></span>
<span>  </span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">n_samples</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="co"># Current parameters</span></span>
<span>    <span class="va">pars_old</span> <span class="op">&lt;-</span> <span class="va">pars</span><span class="op">[</span><span class="va">i</span><span class="op">-</span><span class="fl">1</span>, <span class="op">]</span></span>
<span>    </span>
<span>    <span class="co"># Proposal</span></span>
<span>    <span class="va">pars_new</span> <span class="op">&lt;-</span> <span class="fu">generate_proposal</span><span class="op">(</span><span class="va">pars_old</span>, <span class="va">jump_sd</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># Ratio</span></span>
<span>    <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">get_ratio</span><span class="op">(</span><span class="va">X</span>, <span class="va">pars_old</span>, <span class="va">pars_new</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># Does the sampler move?</span></span>
<span>    <span class="va">move</span> <span class="op">&lt;-</span> <span class="fu">runif</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">&lt;=</span> <span class="va">r</span></span>
<span>    <span class="co"># OR: </span></span>
<span>    <span class="co"># move &lt;- sample(x = c(TRUE, FALSE), size = 1, prob = c(r, 1-r))</span></span>
<span>    </span>
<span>    <span class="kw">if</span><span class="op">(</span><span class="va">move</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">pars</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">pars_new</span></span>
<span>    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>      <span class="va">pars</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">pars_old</span></span>
<span>    <span class="op">}</span></span>
<span>    </span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="va">pars</span> <span class="op">&lt;-</span> <span class="fu">data.frame</span><span class="op">(</span>mu <span class="op">=</span> <span class="va">pars</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, sigma <span class="op">=</span> <span class="va">pars</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw">return</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span> </span>
<span>  </span>
<span><span class="op">}</span></span></code></pre>
</div>
<p>Then, we run the sampler. We’ll use 4 chains with 5000 samples each.
The transition density standard deviation is set to 0.05.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n_samples</span> <span class="op">&lt;-</span> <span class="fl">5000</span></span>
<span><span class="va">n_chains</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="va">jump_sd</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span></span>
<span><span class="co"># Warmup 50%</span></span>
<span><span class="va">warmup</span> <span class="op">&lt;-</span> <span class="fl">0.5</span></span>
<span></span>
<span></span>
<span><span class="co"># Random initials for each chain</span></span>
<span><span class="va">inits</span> <span class="op">&lt;-</span> <span class="fu">apply</span><span class="op">(</span>X <span class="op">=</span> <span class="fu">matrix</span><span class="op">(</span><span class="fu">c</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n_chains</span><span class="op">)</span><span class="op">)</span>,</span>
<span>               MARGIN <span class="op">=</span> <span class="fl">1</span>,</span>
<span>               FUN <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">rnorm</span><span class="op">(</span><span class="fl">2</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">t</span> </span>
<span></span>
<span><span class="co"># Make sure sigma initial &gt;0</span></span>
<span><span class="va">inits</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">abs</span><span class="op">(</span><span class="va">inits</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Run the chains</span></span>
<span><span class="va">samples</span> <span class="op">&lt;-</span> <span class="fu">lapply</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span><span class="op">(</span><span class="va">inits</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">my_df</span> <span class="op">&lt;-</span> <span class="fu">metropolis_sampler</span><span class="op">(</span>X <span class="op">=</span> <span class="va">X</span>,</span>
<span>                              inits <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">inits</span><span class="op">[</span><span class="va">i</span>, <span class="fl">1</span><span class="op">]</span>, <span class="va">inits</span><span class="op">[</span><span class="va">i</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>                              jump_sd <span class="op">=</span> <span class="va">jump_sd</span>,</span>
<span>                              n_samples <span class="op">=</span> <span class="va">n_samples</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>      <span class="fu">data.frame</span><span class="op">(</span><span class="op">)</span></span>
<span>  </span>
<span>  </span>
<span>  <span class="co"># Add column for chain and 50% warmup</span></span>
<span>  <span class="va">my_df</span> <span class="op">&lt;-</span> <span class="va">my_df</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">mutate</span><span class="op">(</span>chain <span class="op">=</span> <span class="fu">as.factor</span><span class="op">(</span><span class="va">i</span><span class="op">)</span>, </span>
<span>           warmup <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="fu">rep</span><span class="op">(</span><span class="cn">TRUE</span>, <span class="fu">nrow</span><span class="op">(</span><span class="va">my_df</span><span class="op">)</span><span class="op">*</span><span class="va">warmup</span><span class="op">)</span>,</span>
<span>                      <span class="fu">rep</span><span class="op">(</span><span class="cn">FALSE</span>, <span class="fu">nrow</span><span class="op">(</span><span class="va">my_df</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">warmup</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">do.call</span><span class="op">(</span><span class="va">rbind</span>, <span class="va">.</span><span class="op">)</span></span></code></pre>
</div>
<p>Plot results. Uncomment the line <code>fill = warmup</code> below so
see the effect of removing the initial 50% of the samples.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">samples_w</span> <span class="op">&lt;-</span> <span class="va">samples</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"par"</span>, value <span class="op">=</span> <span class="st">"value"</span>, <span class="op">-</span><span class="fu">c</span><span class="op">(</span><span class="va">chain</span>, <span class="va">warmup</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Posterior histogram</span></span>
<span></span>
<span><span class="va">p_posterior</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples_w</span>,</span>
<span>                 <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">value</span>,</span>
<span>                     <span class="co"># fill = warmup</span></span>
<span>                     <span class="op">)</span>,</span>
<span>                 bins <span class="op">=</span> <span class="fl">50</span>, alpha <span class="op">=</span> <span class="fl">0.75</span>, position <span class="op">=</span> <span class="st">"identity"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">data.frame</span><span class="op">(</span>par <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span>,</span>
<span>                               value <span class="op">=</span> <span class="fu">c</span><span class="op">(</span><span class="va">mu_true</span>, <span class="va">sigma_true</span><span class="op">)</span><span class="op">)</span>, </span>
<span>             <span class="fu">aes</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">value</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">par</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># p_posterior_chains &lt;- ggplot(samples_l) +</span></span>
<span><span class="co">#   geom_histogram(aes(x = value, fill = chain),</span></span>
<span><span class="co">#                  bins = 50, alpha = 0.75, </span></span>
<span><span class="co">#                  position = "identity") +</span></span>
<span><span class="co">#   geom_vline(data = data.frame(par = c("mu", "sigma"),</span></span>
<span><span class="co">#                                value = c(mu_true, sigma_true)), </span></span>
<span><span class="co">#              aes(xintercept = value)) + </span></span>
<span><span class="co">#   scale_fill_grafify()</span></span>
<span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_posterior</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="fig/mcmc-rendered-unnamed-chunk-8-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure></section><section id="assessing-convergence"><h2 class="section-heading">Assessing convergence<a class="anchor" aria-label="anchor" href="#assessing-convergence"></a>
</h2>
<hr class="half-width">
<p>Although converge is guaranteed in theory, it is not so in
practice.</p>
<p>Like we saw above, unless the chains’ initial values are in high
posterior density areas, the early chain samples will bias the target
distribution estimate. For this reason, it is customary to discard a
proportion of the chain as “warmup.” Often 50% is used and this is also
the default in Stan.</p>
<ul>
<li>Sample autocorrelation, effective sample size
<ul>
<li>ideally, the samples would be independent</li>
</ul>
</li>
<li>Mixing</li>
<li><span class="math inline">\(\hat{R}\)</span></li>
</ul>
<p>Let’s plot the generated trajectories and the true parameter value.
Here, the initial 50% of the chains are colored dim to illustrate the
fact that convergence to the posterior distribution requires long enough
chains.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p_traj</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_path</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">sigma</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span>, alpha <span class="op">=</span> <span class="fl">0.25</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># Post warmup samples</span></span>
<span>  <span class="fu">geom_path</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples</span> <span class="op">%&gt;%</span> <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">sigma</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu_true</span>, y <span class="op">=</span> <span class="va">sigma_true</span><span class="op">)</span>,</span>
<span>             size <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">scale_color_grafify</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Red point = true value"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_traj</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="fig/mcmc-rendered-unnamed-chunk-9-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Next, we’ll make the trace plots, which are comprised of the chains
of individual parameters. The warmup iterations are again colored
dimmer. Trace plots can give quick visual information about the chains.
When there are no converge issues, the trace plots should look like
“hairy caterpillars,” with sample of each chain located around the same
value. In this case everything look ok. A standard convergence metric is
the <span class="math inline">\(\hat{R}\)</span> which compares the
variances between chains and to the variance within each chain. We’ll
omit the definition here but, generally, value <span class="math inline">\(\hat{R} \geq 1.1\)</span> are seen as a sign of
convergence issues. However, with modern samplers such as Stan,
thresholds closer to 1 are recommended (<a href="https://mc-stan.org/rstan/reference/Rhat.html" class="external-link uri">https://mc-stan.org/rstan/reference/Rhat.html</a>).</p>
<p>Clearly convergence is reached fairly quickly after initialization,
in some dozen iterations. Moreover, the chain autocorrelation low. This
is desirable because it implies that the drawn samples are independent.
Another popular convergence metric is the effective sample size. It
quantifies the number of independent samples produced by the
sampler.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Long --&gt; wide format</span></span>
<span><span class="va">samples_w</span> <span class="op">&lt;-</span> <span class="va">samples</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sample <span class="op">=</span> <span class="fu">rep</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n_samples</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">gather</span><span class="op">(</span>key <span class="op">=</span> <span class="st">"parameter"</span>, value <span class="op">=</span> <span class="st">"value"</span>, <span class="op">-</span><span class="fu">c</span><span class="op">(</span><span class="va">chain</span>, <span class="va">warmup</span>, <span class="va">sample</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Trace plot</span></span>
<span><span class="va">p_trace</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples_w</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">sample</span>, y <span class="op">=</span> <span class="va">value</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span>, alpha <span class="op">=</span> <span class="fl">0.25</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">samples_w</span> <span class="op">%&gt;%</span> <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">sample</span>, y <span class="op">=</span> <span class="va">value</span>, color <span class="op">=</span> <span class="va">chain</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="va">chain</span> <span class="op">~</span> <span class="va">parameter</span>,</span>
<span>             scales <span class="op">=</span> <span class="st">"free"</span>,</span>
<span>             ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">scale_color_grafify</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="va">p_trace</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="fig/mcmc-rendered-unnamed-chunk-10-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Let’s compute the number of rejected proposals to get some idea about
the efficiency of the algorithm. The less samples are rejected, the more
efficient the sampler performs.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Proportion of post-warmup samples where the proposal was rejected</span></span>
<span><span class="fu">sum</span><span class="op">(</span><span class="fu">table</span><span class="op">(</span><span class="va">samples</span> <span class="op">%&gt;%</span></span>
<span>            <span class="fu">filter</span><span class="op">(</span><span class="va">warmup</span> <span class="op">==</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>            <span class="fu">pull</span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="va">n_chains</span><span class="op">*</span><span class="va">n_samples</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">warmup</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] 0.3943</code></pre>
</div>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<p>Try different proposal distributions (e.g. 0.005, 0.5) standard
deviations in the MCMC example above. How does this affect the inference
and convergence? Why?</p>
</div>
</div>
</div>
</section><section id="hamiltonian-monte-carlo"><h2 class="section-heading">Hamiltonian Monte Carlo<a class="anchor" aria-label="anchor" href="#hamiltonian-monte-carlo"></a>
</h2>
<hr class="half-width">
<p>Hamiltonian Monte Carlo (HMC) is a variant of the Metropolis-Hastings
algorithm implemented in Stan. The defining feature is the elaborate
scheme it uses to generate proposals. Briefly, the idea is to simulate
the dynamics of a particle moving in a potential landscape defined by
the posterior. At each iteration, the particle is given a random
momentum vector and then its dynamics are simulated forward for some
time. The end of the trajectory is then taken as the proposal value.</p>
<p>Compared to the random walk Metropolis-Hastings we implemented in
this episode, HMC is very efficient. The main advantages of HMC is its
ability to explore high-dimensional spaces more effectively, making it
especially useful in complex models with many parameters</p>
<p>A type of convergence criterion exclusive to HMC are divergent
transitions. In region of the parameter space where the posterior has
high curvature, the simulated particle dynamics can produce spurious
transitions which do not represent the posterior accurately. Such
transitions are called divergent and signal that the particular area of
parameter space is not explored accurately. Stan provides information
about divergent transitions.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li><p>MCMC is ….</p></li>
<li>
<p>Convergence should be monitored</p>
<ul>
<li>mixing: <span class="math inline">\(\hat{R}\)</span>
</li>
<li>divergent transitions</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section><section id="reading"><h2 class="section-heading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li><p>See interactive visualization of different MCMC algorithms: <a href="https://chi-feng.github.io/mcmc-demo/app.html" class="external-link uri">https://chi-feng.github.io/mcmc-demo/app.html</a></p></li>
<li><p>Statistical Rethinking</p></li>
<li><p>BDA3</p></li>
<li><p>Bayes Rules!</p></li>
</ul>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 --></section></section><section id="aio-hierarchical-models"><p>Content from <a href="hierarchical-models.html">Hierarchical Models</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/hierarchical-models.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are Bayesian hierarchical models?</li>
<li>What are they good for?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the idea of hierarchical models</li>
<li>Learn how to build and with hierarchical models with Stan</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="hierachical-models"><h2 class="section-heading">Hierachical models<a class="anchor" aria-label="anchor" href="#hierachical-models"></a>
</h2>
<hr class="half-width">
<p>Bayesian hierarchical models are a class of models suited for
modeling scenarios where the study population consists of separate but
related groups. Hierarchical structure refers to this organization of
data into multiple levels or groups, where each level can have its own
set of parameters. These parameters are connected trough a common prior
that is also learned when fitting the model. Some or all of the
hyperparameters of the priors are unknown model parameters and they are
given hyperpriors.</p>
<p>One key advantage of Bayesian hierarchical models is their ability to
borrow strength across groups. By pooling information from multiple
groups, these models can provide more stable estimates, especially when
individual groups have limited data. This pooling of information is
particularly beneficial when there are sparse observations or when data
from different groups exhibit similar patterns.</p>
<p>Examples of scenarios where hierarchical model could be a natural
choice:</p>
</section><section id="example-hierarchical-binomial-model"><h2 class="section-heading">Example: Hierarchical binomial model<a class="anchor" aria-label="anchor" href="#example-hierarchical-binomial-model"></a>
</h2>
<hr class="half-width">
<p>Let’s take a look at a hierarchical binomial model. Let <span class="math inline">\(X = \{X_1, X_2, \ldots, X_N\}\)</span> be a set of
observations representing the number of successes in <span class="math inline">\(n\)</span> Bernoulli trials in <span class="math inline">\(N\)</span> different scenarios. We assume that
these scenarios are not identical, so there are <span class="math inline">\(N\)</span> unknown probability parameters, <span class="math inline">\(p_1, p_2, \ldots, p_N\)</span>. This model can be
specified as follows.</p>
<p><span class="math display">\[\begin{align}
X_i &amp;\sim Binom(n, p_i) \\
p_i &amp;\sim Beta(\alpha, \beta) \\
\alpha, \beta &amp;\sim Gamma(2, 1).
\end{align}\]</span></p>
<p>The difference to the binomial model as used in the previous episodes
is that the parameters <span class="math inline">\(p_i\)</span> have a
prior with unknown hyperparameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta.\)</span> These hyperparameters are given a
<span class="math inline">\(Gamma\)</span> prior and learned in the
inference.</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge1"></a>
</h3>
<div class="callout-content">
<p>Hierarchical models are also called partially pooled models in
contrast to unpooled and completely pooled models. The former mean that
the model parameters are assumed to be completely independent, while in
the latter type the (parallel) parameters are equal. Write the unpooled
and completely pooled variants of the hierarchical binomial model.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Unpooled:</p>
<p><span class="math display">\[\begin{align}
X_i &amp;\sim Binom(n, p_i) \\
p_i &amp;\sim Beta(2, 2) \\
\end{align}\]</span></p>
<p>Completely pooled:</p>
<p><span class="math display">\[\begin{align}
X_i &amp;\sim Binom(n, p) \\
p &amp;\sim Beta(2, 2) \\
\end{align}\]</span></p>
</div>
</div>
</div>
</div>
<p>Let’s then implement the hierarchical, along with the unpooled and
completely pooled binomial model in Stan.</p>
<p>Hierarchical binomial model</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">STAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode stan" tabindex="0"><code class="sourceCode stan"></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">sampling</span><span class="op">(</span><span class="va">hierarchical_binomial_model</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">ERROR<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="error" tabindex="0"><code>Error in sampling(hierarchical_binomial_model): could not find function "sampling"</code></pre>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>point 1</li>
</ul>
</div>
</div>
</div>
</section><section id="reading"><h2 class="section-heading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 --></section></section><section id="aio-model-critisism"><p>Content from <a href="model-critisism.html">Model checking</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/model-critisism.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is model checking?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Prior/Posterior predictive check</li>
<li>Learn how assess model fit
<ul>
<li>Bayesian residuals?</li>
</ul>
</li>
<li>Model comparison with
<ul>
<li>AIC, BIC, WAIC</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="posterior-predictive-check"><h2 class="section-heading">Posterior predictive check<a class="anchor" aria-label="anchor" href="#posterior-predictive-check"></a>
</h2>
<hr class="half-width">
<p>Gelman: “If the model fits, then replicated data generated under the
model should look similar to observed data.”</p>
<p>Idea: simulate data from the posterior predictive distribution and
compare it to the observed data. Discrepancies between the simulated and
observed data imply shortcomings in the model.</p>
<p>Posterior predictive distribution presented in Episode Working with
samples.</p>
</section><section id="information-criteria"><h2 class="section-heading">Information criteria<a class="anchor" aria-label="anchor" href="#information-criteria"></a>
</h2>
<hr class="half-width">
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>point 1</li>
</ul>
</div>
</div>
</div>
</section><section id="reading"><h2 class="section-heading">Reading<a class="anchor" aria-label="anchor" href="#reading"></a>
</h2>
<hr class="half-width">
<ul>
<li>Statistical Rethinking: Ch. 7</li>
<li>BDA3: p.143: 6.3 Posterior predictive checking</li>
</ul>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 --></section></section><section id="aio-gaussian-processes"><p>Content from <a href="gaussian-processes.html">Gaussian processes</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/gaussian-processes.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are Gaussian processes?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Non-parameteric regression</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Add text</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge1"></a>
</h3>
<div class="callout-content">
<p>You can define a challenge here</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>… and a solution here</p>
</div>
</div>
</div>
</div>
<p>More text</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<p>Discussion points</p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>point 1</li>
</ul>
</div>
</div>
</div></section><section id="aio-other-topics"><p>Content from <a href="other-topics.html">Other topics</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/other-topics.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What next?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn more</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Add text</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge1"></a>
</h3>
<div class="callout-content">
<p>You can define a challenge here</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>… and a solution here</p>
</div>
</div>
</div>
</div>
<p>More text</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<p>Discussion poitns</p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>point 1</li>
</ul>
</div>
</div>
</div></section><section id="aio-recommended-reading"><p>Content from <a href="recommended-reading.html">Recommended reading</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/recommended-reading.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Where can I learn more about statistical and probabilistic
programming?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Provide links to other materials where learners can deepen their
skills in probabilistic programming.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="books"><h2 class="section-heading">Books<a class="anchor" aria-label="anchor" href="#books"></a>
</h2>
<hr class="half-width">
<ul>
<li>Gelman</li>
<li>Statistical Rethinking</li>
<li>Bayes Rules!</li>
</ul></section><section id="links"><h2 class="section-heading">Links<a class="anchor" aria-label="anchor" href="#links"></a>
</h2>
<hr class="half-width">
<ul>
<li>An applet illustrating different MCMC variants: <a href="https://chi-feng.github.io/mcmc-demo/app.html" class="external-link uri">https://chi-feng.github.io/mcmc-demo/app.html</a>
</li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>There are loads of additional material available</li>
</ul>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></section><section id="aio-exercises"><p>Content from <a href="exercises.html">exercises</a></p>
<hr>
<p>Last updated on 2024-01-16 |
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/episodes/exercises.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I get routine in probabilistic programming?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<p>The purpose of this episode is to provide material for practicing
probabilistic programming. The exercises are listed approximately based
on the episode they refer to.</p>
</div>
</div>
</div>
</div>
</div></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/edit/main/README.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/statistical-probabilistic-programming-r/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:velait@utu.fi">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.2" class="external-link">sandpaper (0.16.2)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.3" class="external-link">pegboard (0.7.3)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.1" class="external-link">varnish (1.0.1)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries-incubator.github.io/statistical-probabilistic-programming-r/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/statistical-probabilistic-programming-r/aio.html",
  "identifier": "https://carpentries-incubator.github.io/statistical-probabilistic-programming-r/aio.html",
  "dateCreated": "2024-01-16",
  "dateModified": "2024-01-16",
  "datePublished": "2024-01-16"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code -->
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

